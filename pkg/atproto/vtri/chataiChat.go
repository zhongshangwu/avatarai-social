// Code generated by cmd/lexgen (see Makefile's lexgen); DO NOT EDIT.

package vtri

// schema: app.vtri.chat.aiChat

import (
	"encoding/json"
	"fmt"

	"github.com/bluesky-social/indigo/lex/util"
)

// ChatAiChat_Annotation is a "Annotation" in the app.vtri.chat.aiChat schema.
//
// An annotation in the text output
type ChatAiChat_Annotation struct {
	ChatAiChat_FileCitationBody *ChatAiChat_FileCitationBody
	ChatAiChat_UrlCitationBody  *ChatAiChat_UrlCitationBody
}

func (t *ChatAiChat_Annotation) MarshalJSON() ([]byte, error) {
	if t.ChatAiChat_FileCitationBody != nil {
		t.ChatAiChat_FileCitationBody.LexiconTypeID = "app.vtri.chat.aiChat#FileCitationBody"
		return json.Marshal(t.ChatAiChat_FileCitationBody)
	}
	if t.ChatAiChat_UrlCitationBody != nil {
		t.ChatAiChat_UrlCitationBody.LexiconTypeID = "app.vtri.chat.aiChat#UrlCitationBody"
		return json.Marshal(t.ChatAiChat_UrlCitationBody)
	}
	return nil, fmt.Errorf("cannot marshal empty enum")
}
func (t *ChatAiChat_Annotation) UnmarshalJSON(b []byte) error {
	typ, err := util.TypeExtract(b)
	if err != nil {
		return err
	}

	switch typ {
	case "app.vtri.chat.aiChat#FileCitationBody":
		t.ChatAiChat_FileCitationBody = new(ChatAiChat_FileCitationBody)
		return json.Unmarshal(b, t.ChatAiChat_FileCitationBody)
	case "app.vtri.chat.aiChat#UrlCitationBody":
		t.ChatAiChat_UrlCitationBody = new(ChatAiChat_UrlCitationBody)
		return json.Unmarshal(b, t.ChatAiChat_UrlCitationBody)

	default:
		return nil
	}
}

// ChatAiChat_FileCitationBody is a "FileCitationBody" in the app.vtri.chat.aiChat schema.
//
// # A citation to a file
//
// RECORDTYPE: ChatAiChat_FileCitationBody
type ChatAiChat_FileCitationBody struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#FileCitationBody" cborgen:"$type,const=app.vtri.chat.aiChat#FileCitationBody"`
	// fileId: The ID of the file
	FileId string `json:"fileId" cborgen:"fileId"`
	// index: The index of the file in the list of files
	Index int64 `json:"index" cborgen:"index"`
	// type: The type of the file citation. Always `file_citation`
	Type string `json:"type" cborgen:"type"`
}

// ChatAiChat_FunctionToolCall is a "FunctionToolCall" in the app.vtri.chat.aiChat schema.
//
// # A function tool call from the model
//
// RECORDTYPE: ChatAiChat_FunctionToolCall
type ChatAiChat_FunctionToolCall struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#FunctionToolCall" cborgen:"$type,const=app.vtri.chat.aiChat#FunctionToolCall"`
	// arguments: The arguments to the function as a JSON string
	Arguments *string `json:"arguments,omitempty" cborgen:"arguments,omitempty"`
	// id: The unique ID of the function tool call
	Id string `json:"id" cborgen:"id"`
	// name: The name of the function being called
	Name string `json:"name" cborgen:"name"`
	// status: The status of the function tool call. One of `in_progress`, `completed`, or `incomplete`
	Status string `json:"status" cborgen:"status"`
	// type: The type of the output item. Always `tool_call`
	Type string `json:"type" cborgen:"type"`
}

// ChatAiChat_InputFileContent is a "InputFileContent" in the app.vtri.chat.aiChat schema.
//
// 模型的文件输入
//
// RECORDTYPE: ChatAiChat_InputFileContent
type ChatAiChat_InputFileContent struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#InputFileContent" cborgen:"$type,const=app.vtri.chat.aiChat#InputFileContent"`
	// fileId: 要发送到模型的文件的ID
	FileId string `json:"fileId" cborgen:"fileId"`
	// type: 输入项的类型。始终为`input_file`
	Type string `json:"type" cborgen:"type"`
}

// ChatAiChat_InputImageContent is a "InputImageContent" in the app.vtri.chat.aiChat schema.
//
// 模型的图像输入
//
// RECORDTYPE: ChatAiChat_InputImageContent
type ChatAiChat_InputImageContent struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#InputImageContent" cborgen:"$type,const=app.vtri.chat.aiChat#InputImageContent"`
	// detail: 要发送到模型的图像的细节级别。可以是`high`、`low`或`auto`之一。默认为`auto`
	Detail string `json:"detail" cborgen:"detail"`
	// fileId: 要发送到模型的文件的ID
	FileId *string `json:"fileId,omitempty" cborgen:"fileId,omitempty"`
	// imageUrl: 图像URL
	ImageUrl *string `json:"imageUrl,omitempty" cborgen:"imageUrl,omitempty"`
	// type: 输入项的类型。始终为`input_image`
	Type string `json:"type" cborgen:"type"`
}

// ChatAiChat_InputMessage is a "InputMessage" in the app.vtri.chat.aiChat schema.
//
// 具有指示层次结构角色的模型输入消息
//
// RECORDTYPE: ChatAiChat_InputMessage
type ChatAiChat_InputMessage struct {
	LexiconTypeID string                                  `json:"$type,const=app.vtri.chat.aiChat#InputMessage" cborgen:"$type,const=app.vtri.chat.aiChat#InputMessage"`
	Content       []*ChatAiChat_InputMessage_Content_Elem `json:"content" cborgen:"content"`
	// role: 消息输入的角色。可以是`user`、`system`或`developer`之一
	Role string `json:"role" cborgen:"role"`
	// status: 项目的状态。可以是`in_progress`、`completed`或`incomplete`之一
	Status *string `json:"status,omitempty" cborgen:"status,omitempty"`
	// type: 消息输入的类型。始终设置为`message`
	Type *string `json:"type,omitempty" cborgen:"type,omitempty"`
}

type ChatAiChat_InputMessage_Content_Elem struct {
	ChatAiChat_InputTextContent  *ChatAiChat_InputTextContent
	ChatAiChat_InputImageContent *ChatAiChat_InputImageContent
	ChatAiChat_InputFileContent  *ChatAiChat_InputFileContent
}

func (t *ChatAiChat_InputMessage_Content_Elem) MarshalJSON() ([]byte, error) {
	if t.ChatAiChat_InputTextContent != nil {
		t.ChatAiChat_InputTextContent.LexiconTypeID = "app.vtri.chat.aiChat#InputTextContent"
		return json.Marshal(t.ChatAiChat_InputTextContent)
	}
	if t.ChatAiChat_InputImageContent != nil {
		t.ChatAiChat_InputImageContent.LexiconTypeID = "app.vtri.chat.aiChat#InputImageContent"
		return json.Marshal(t.ChatAiChat_InputImageContent)
	}
	if t.ChatAiChat_InputFileContent != nil {
		t.ChatAiChat_InputFileContent.LexiconTypeID = "app.vtri.chat.aiChat#InputFileContent"
		return json.Marshal(t.ChatAiChat_InputFileContent)
	}
	return nil, fmt.Errorf("cannot marshal empty enum")
}
func (t *ChatAiChat_InputMessage_Content_Elem) UnmarshalJSON(b []byte) error {
	typ, err := util.TypeExtract(b)
	if err != nil {
		return err
	}

	switch typ {
	case "app.vtri.chat.aiChat#InputTextContent":
		t.ChatAiChat_InputTextContent = new(ChatAiChat_InputTextContent)
		return json.Unmarshal(b, t.ChatAiChat_InputTextContent)
	case "app.vtri.chat.aiChat#InputImageContent":
		t.ChatAiChat_InputImageContent = new(ChatAiChat_InputImageContent)
		return json.Unmarshal(b, t.ChatAiChat_InputImageContent)
	case "app.vtri.chat.aiChat#InputFileContent":
		t.ChatAiChat_InputFileContent = new(ChatAiChat_InputFileContent)
		return json.Unmarshal(b, t.ChatAiChat_InputFileContent)

	default:
		return nil
	}
}

// ChatAiChat_InputTextContent is a "InputTextContent" in the app.vtri.chat.aiChat schema.
//
// 模型的文本输入
//
// RECORDTYPE: ChatAiChat_InputTextContent
type ChatAiChat_InputTextContent struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#InputTextContent" cborgen:"$type,const=app.vtri.chat.aiChat#InputTextContent"`
	// text: 模型的文本输入
	Text string `json:"text" cborgen:"text"`
	// type: 输入项的类型。始终为`input_text`
	Type string `json:"type" cborgen:"type"`
}

// RECORDTYPE: ChatAiChat_Message
type ChatAiChat_Message struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat" cborgen:"$type,const=app.vtri.chat.aiChat"`
	// createdAt: 创建时间
	CreatedAt int64                     `json:"createdAt" cborgen:"createdAt"`
	Error     *ChatAiChat_ResponseError `json:"error" cborgen:"error"`
	// id: Unique identifier for this AI Chat Message
	Id string `json:"id" cborgen:"id"`
	// incompleteDetails: Details about why the response is incomplete
	IncompleteDetails *ChatAiChat_Message_IncompleteDetails `json:"incompleteDetails" cborgen:"incompleteDetails"`
	// interruptType: 消息是否有被中断
	InterruptType int64 `json:"interruptType" cborgen:"interruptType"`
	// messageId: 消息ID, 引用 message.id
	MessageId string `json:"messageId" cborgen:"messageId"`
	// messageItems: An array of content items generated by the model
	MessageItems []*ChatAiChat_OutputItem `json:"messageItems" cborgen:"messageItems"`
	// metadata: Additional metadata for the response
	Metadata *ChatAiChat_Message_Metadata `json:"metadata" cborgen:"metadata"`
	// role: 消息角色
	Role string `json:"role" cborgen:"role"`
	// status: The status of the response generation. One of `completed`, `failed`, `in_progress`, or `incomplete`
	Status string `json:"status" cborgen:"status"`
	// text: 消息内容(纯文本)
	Text string `json:"text" cborgen:"text"`
	// tools: The tools available to the model
	Tools []*ChatAiChat_Message_Tools_Elem `json:"tools" cborgen:"tools"`
	// updatedAt: 更新时间
	UpdatedAt int64                     `json:"updatedAt" cborgen:"updatedAt"`
	Usage     *ChatAiChat_ResponseUsage `json:"usage" cborgen:"usage"`
	// userId: 用户ID (可能是用户ID， 也可以是 AssistantID)
	UserId string `json:"userId" cborgen:"userId"`
}

// Details about why the response is incomplete
type ChatAiChat_Message_IncompleteDetails struct {
	// reason: The reason why the response is incomplete
	Reason *string `json:"reason,omitempty" cborgen:"reason,omitempty"`
}

// Additional metadata for the response
type ChatAiChat_Message_Metadata struct {
}

type ChatAiChat_Message_Tools_Elem struct {
}

// ChatAiChat_OutputContent is a "OutputContent" in the app.vtri.chat.aiChat schema.
//
// Content output from the model
type ChatAiChat_OutputContent struct {
	ChatAiChat_OutputTextContent *ChatAiChat_OutputTextContent
	ChatAiChat_RefusalContent    *ChatAiChat_RefusalContent
}

func (t *ChatAiChat_OutputContent) MarshalJSON() ([]byte, error) {
	if t.ChatAiChat_OutputTextContent != nil {
		t.ChatAiChat_OutputTextContent.LexiconTypeID = "app.vtri.chat.aiChat#OutputTextContent"
		return json.Marshal(t.ChatAiChat_OutputTextContent)
	}
	if t.ChatAiChat_RefusalContent != nil {
		t.ChatAiChat_RefusalContent.LexiconTypeID = "app.vtri.chat.aiChat#RefusalContent"
		return json.Marshal(t.ChatAiChat_RefusalContent)
	}
	return nil, fmt.Errorf("cannot marshal empty enum")
}
func (t *ChatAiChat_OutputContent) UnmarshalJSON(b []byte) error {
	typ, err := util.TypeExtract(b)
	if err != nil {
		return err
	}

	switch typ {
	case "app.vtri.chat.aiChat#OutputTextContent":
		t.ChatAiChat_OutputTextContent = new(ChatAiChat_OutputTextContent)
		return json.Unmarshal(b, t.ChatAiChat_OutputTextContent)
	case "app.vtri.chat.aiChat#RefusalContent":
		t.ChatAiChat_RefusalContent = new(ChatAiChat_RefusalContent)
		return json.Unmarshal(b, t.ChatAiChat_RefusalContent)

	default:
		return nil
	}
}

//func (t *ChatAiChat_OutputContent) MarshalCBOR(w io.Writer) error {
//
//	if t == nil {
//		_, err := w.Write(cbg.CborNull)
//		return err
//	}
//	if t.ChatAiChat_OutputTextContent != nil {
//		return t.ChatAiChat_OutputTextContent.MarshalCBOR(w)
//	}
//	if t.ChatAiChat_RefusalContent != nil {
//		return t.ChatAiChat_RefusalContent.MarshalCBOR(w)
//	}
//	return fmt.Errorf("cannot cbor marshal empty enum")
//}
//func (t *ChatAiChat_OutputContent) UnmarshalCBOR(r io.Reader) error {
//	typ, b, err := util.CborTypeExtractReader(r)
//	if err != nil {
//		return err
//	}
//
//	switch typ {
//	case "app.vtri.chat.aiChat#OutputTextContent":
//		t.ChatAiChat_OutputTextContent = new(ChatAiChat_OutputTextContent)
//		return t.ChatAiChat_OutputTextContent.UnmarshalCBOR(bytes.NewReader(b))
//	case "app.vtri.chat.aiChat#RefusalContent":
//		t.ChatAiChat_RefusalContent = new(ChatAiChat_RefusalContent)
//		return t.ChatAiChat_RefusalContent.UnmarshalCBOR(bytes.NewReader(b))
//
//	default:
//		return nil
//	}
//}

// ChatAiChat_OutputItem is a "OutputItem" in the app.vtri.chat.aiChat schema.
//
// An output item from the model
type ChatAiChat_OutputItem struct {
	ChatAiChat_OutputMessage    *ChatAiChat_OutputMessage
	ChatAiChat_FunctionToolCall *ChatAiChat_FunctionToolCall
	ChatAiChat_ReasoningItem    *ChatAiChat_ReasoningItem
}

func (t *ChatAiChat_OutputItem) MarshalJSON() ([]byte, error) {
	if t.ChatAiChat_OutputMessage != nil {
		t.ChatAiChat_OutputMessage.LexiconTypeID = "app.vtri.chat.aiChat#OutputMessage"
		return json.Marshal(t.ChatAiChat_OutputMessage)
	}
	if t.ChatAiChat_FunctionToolCall != nil {
		t.ChatAiChat_FunctionToolCall.LexiconTypeID = "app.vtri.chat.aiChat#FunctionToolCall"
		return json.Marshal(t.ChatAiChat_FunctionToolCall)
	}
	if t.ChatAiChat_ReasoningItem != nil {
		t.ChatAiChat_ReasoningItem.LexiconTypeID = "app.vtri.chat.aiChat#ReasoningItem"
		return json.Marshal(t.ChatAiChat_ReasoningItem)
	}
	return nil, fmt.Errorf("cannot marshal empty enum")
}
func (t *ChatAiChat_OutputItem) UnmarshalJSON(b []byte) error {
	typ, err := util.TypeExtract(b)
	if err != nil {
		return err
	}

	switch typ {
	case "app.vtri.chat.aiChat#OutputMessage":
		t.ChatAiChat_OutputMessage = new(ChatAiChat_OutputMessage)
		return json.Unmarshal(b, t.ChatAiChat_OutputMessage)
	case "app.vtri.chat.aiChat#FunctionToolCall":
		t.ChatAiChat_FunctionToolCall = new(ChatAiChat_FunctionToolCall)
		return json.Unmarshal(b, t.ChatAiChat_FunctionToolCall)
	case "app.vtri.chat.aiChat#ReasoningItem":
		t.ChatAiChat_ReasoningItem = new(ChatAiChat_ReasoningItem)
		return json.Unmarshal(b, t.ChatAiChat_ReasoningItem)

	default:
		return nil
	}
}

//func (t *ChatAiChat_OutputItem) MarshalCBOR(w io.Writer) error {
//
//	if t == nil {
//		_, err := w.Write(cbg.CborNull)
//		return err
//	}
//	if t.ChatAiChat_OutputMessage != nil {
//		return t.ChatAiChat_OutputMessage.MarshalCBOR(w)
//	}
//	if t.ChatAiChat_FunctionToolCall != nil {
//		return t.ChatAiChat_FunctionToolCall.MarshalCBOR(w)
//	}
//	if t.ChatAiChat_ReasoningItem != nil {
//		return t.ChatAiChat_ReasoningItem.MarshalCBOR(w)
//	}
//	return fmt.Errorf("cannot cbor marshal empty enum")
//}
//func (t *ChatAiChat_OutputItem) UnmarshalCBOR(r io.Reader) error {
//	typ, b, err := util.CborTypeExtractReader(r)
//	if err != nil {
//		return err
//	}
//
//	switch typ {
//	case "app.vtri.chat.aiChat#OutputMessage":
//		t.ChatAiChat_OutputMessage = new(ChatAiChat_OutputMessage)
//		return t.ChatAiChat_OutputMessage.UnmarshalCBOR(bytes.NewReader(b))
//	case "app.vtri.chat.aiChat#FunctionToolCall":
//		t.ChatAiChat_FunctionToolCall = new(ChatAiChat_FunctionToolCall)
//		return t.ChatAiChat_FunctionToolCall.UnmarshalCBOR(bytes.NewReader(b))
//	case "app.vtri.chat.aiChat#ReasoningItem":
//		t.ChatAiChat_ReasoningItem = new(ChatAiChat_ReasoningItem)
//		return t.ChatAiChat_ReasoningItem.UnmarshalCBOR(bytes.NewReader(b))
//
//	default:
//		return nil
//	}
//}

// ChatAiChat_OutputMessage is a "OutputMessage" in the app.vtri.chat.aiChat schema.
//
// # An output message from the model
//
// RECORDTYPE: ChatAiChat_OutputMessage
type ChatAiChat_OutputMessage struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#OutputMessage" cborgen:"$type,const=app.vtri.chat.aiChat#OutputMessage"`
	// content: The content of the output message
	Content []*ChatAiChat_OutputContent `json:"content" cborgen:"content"`
	// id: The unique ID of the output message
	Id string `json:"id" cborgen:"id"`
	// role: The role of the output message. Always `assistant`
	Role string `json:"role" cborgen:"role"`
	// status: The status of the message input. One of `in_progress`, `completed`, or `incomplete`
	Status string `json:"status" cborgen:"status"`
	// type: The type of the output message. Always `message`
	Type string `json:"type" cborgen:"type"`
}

// ChatAiChat_OutputTextContent is a "OutputTextContent" in the app.vtri.chat.aiChat schema.
//
// # A text output from the model
//
// RECORDTYPE: ChatAiChat_OutputTextContent
type ChatAiChat_OutputTextContent struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#OutputTextContent" cborgen:"$type,const=app.vtri.chat.aiChat#OutputTextContent"`
	// annotations: The annotations of the text output
	Annotations []*ChatAiChat_Annotation `json:"annotations,omitempty" cborgen:"annotations,omitempty"`
	// text: The text output from the model
	Text string `json:"text" cborgen:"text"`
	// type: The type of the output text. Always `output_text`
	Type string `json:"type" cborgen:"type"`
}

// ChatAiChat_ReasoningItem is a "ReasoningItem" in the app.vtri.chat.aiChat schema.
//
// # A description of the chain of thought used by a reasoning model while generating a response
//
// RECORDTYPE: ChatAiChat_ReasoningItem
type ChatAiChat_ReasoningItem struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#ReasoningItem" cborgen:"$type,const=app.vtri.chat.aiChat#ReasoningItem"`
	// id: The unique identifier of the reasoning content
	Id string `json:"id" cborgen:"id"`
	// status: The status of the item. One of `in_progress`, `completed`, or `incomplete`
	Status *string `json:"status,omitempty" cborgen:"status,omitempty"`
	// summary: Reasoning text contents
	Summary []*ChatAiChat_ReasoningItem_Summary_Elem `json:"summary" cborgen:"summary"`
	// type: The type of the object. Always `reasoning`
	Type string `json:"type" cborgen:"type"`
}

type ChatAiChat_ReasoningItem_Summary_Elem struct {
	// text: A short summary of the reasoning used by the model when generating the response
	Text string `json:"text" cborgen:"text"`
	// type: The type of the object. Always `summary_text`
	Type string `json:"type" cborgen:"type"`
}

// ChatAiChat_RefusalContent is a "RefusalContent" in the app.vtri.chat.aiChat schema.
//
// # A refusal from the model
//
// RECORDTYPE: ChatAiChat_RefusalContent
type ChatAiChat_RefusalContent struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#RefusalContent" cborgen:"$type,const=app.vtri.chat.aiChat#RefusalContent"`
	// refusal: The refusal explanation from the model
	Refusal string `json:"refusal" cborgen:"refusal"`
	// type: The type of the refusal. Always `refusal`
	Type string `json:"type" cborgen:"type"`
}

// ChatAiChat_ResponseError is a "ResponseError" in the app.vtri.chat.aiChat schema.
//
// An error object returned when the model fails to generate a Response
type ChatAiChat_ResponseError struct {
	// code: The error code
	Code *string `json:"code" cborgen:"code"`
	// message: A human-readable description of the error
	Message string `json:"message" cborgen:"message"`
}

// ChatAiChat_ResponseUsage is a "ResponseUsage" in the app.vtri.chat.aiChat schema.
//
// Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used
type ChatAiChat_ResponseUsage struct {
	// inputTokens: The number of input tokens
	InputTokens int64 `json:"inputTokens" cborgen:"inputTokens"`
	// inputTokensDetails: A detailed breakdown of the input tokens
	InputTokensDetails *ChatAiChat_ResponseUsage_InputTokensDetails `json:"inputTokensDetails" cborgen:"inputTokensDetails"`
	// outputTokens: The number of output tokens
	OutputTokens int64 `json:"outputTokens" cborgen:"outputTokens"`
	// outputTokensDetails: A detailed breakdown of the output tokens
	OutputTokensDetails *ChatAiChat_ResponseUsage_OutputTokensDetails `json:"outputTokensDetails" cborgen:"outputTokensDetails"`
	// totalTokens: The total number of tokens used
	TotalTokens int64 `json:"totalTokens" cborgen:"totalTokens"`
}

// A detailed breakdown of the input tokens
type ChatAiChat_ResponseUsage_InputTokensDetails struct {
	// cachedTokens: The number of tokens that were retrieved from the cache
	CachedTokens int64 `json:"cachedTokens" cborgen:"cachedTokens"`
}

// A detailed breakdown of the output tokens
type ChatAiChat_ResponseUsage_OutputTokensDetails struct {
	// reasoningTokens: The number of reasoning tokens
	ReasoningTokens int64 `json:"reasoningTokens" cborgen:"reasoningTokens"`
}

// ChatAiChat_UrlCitationBody is a "UrlCitationBody" in the app.vtri.chat.aiChat schema.
//
// # A citation for a web resource used to generate a model response
//
// RECORDTYPE: ChatAiChat_UrlCitationBody
type ChatAiChat_UrlCitationBody struct {
	LexiconTypeID string `json:"$type,const=app.vtri.chat.aiChat#UrlCitationBody" cborgen:"$type,const=app.vtri.chat.aiChat#UrlCitationBody"`
	// endIndex: The index of the last character of the URL citation in the message
	EndIndex int64 `json:"endIndex" cborgen:"endIndex"`
	// startIndex: The index of the first character of the URL citation in the message
	StartIndex int64 `json:"startIndex" cborgen:"startIndex"`
	// title: The title of the web resource
	Title string `json:"title" cborgen:"title"`
	// type: The type of the URL citation. Always `url_citation`
	Type string `json:"type" cborgen:"type"`
	// url: The URL of the web resource
	Url string `json:"url" cborgen:"url"`
}
